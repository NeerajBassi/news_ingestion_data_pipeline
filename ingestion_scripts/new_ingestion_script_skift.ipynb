{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf63a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ab7de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b5ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_DIR = r\"C:/Users/HP/Documents/repos/news_ingestion_data_pipeline/data\"\n",
    "DB_FILE = \"articles.db\"\n",
    "DB_PATH = os.path.join(DB_DIR, DB_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8439f4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2025-08-01T17:19:21', True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_latest_news_time():\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        cursor = conn.execute(\"SELECT MAX(News_published_time) FROM articles\")\n",
    "        result = cursor.fetchone()\n",
    "        if result[0]:\n",
    "            incremental = True\n",
    "            latest_timestamp = result[0]\n",
    "        else:\n",
    "            incremental = False\n",
    "            latest_timestamp = '2025-07-25T00:00:00'\n",
    "        return (latest_timestamp, incremental)\n",
    "    \n",
    "get_latest_news_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "713b3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date_str, source= 'skift'):\n",
    "    \"\"\"\n",
    "    Converts date string like 'July 28, 2025' to datetime object.\n",
    "    Return None if parse fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if source == \"Phocusewire\":\n",
    "            return datetime.strptime(date_str.strip(), \"%B %d, %Y\")\n",
    "        else:\n",
    "            return datetime.fromisoformat(date_str)\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "def generate_article_id(url):\n",
    "    return hashlib.md5(url.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "\n",
    "def datetime_to_iso_with_time(dt):\n",
    "    \"\"\"\n",
    "    Convert a datetime object to ISO8601 string with a fixed time part.\n",
    "\n",
    "    Args:\n",
    "        dt (datetime): A datetime object (date part used).\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted ISO8601 string in 'YYYY-MM-DDTHH:MM:SS' format\n",
    "    \"\"\"\n",
    "    date_part = dt.strftime(\"%Y-%m-%d\")\n",
    "    time_str = dt.strftime(\"%H:%M:%S\")\n",
    "    return f\"{date_part}T{time_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5410a765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-07-29T11:21:16'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str = \"2025-07-29T11:21:16-04:00\"\n",
    "def drop_timezone(date_str):\n",
    "    date_str = datetime.fromisoformat(date_str)\n",
    "    return date_str.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "drop_timezone(date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7afb1342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-29T11:21:16\n",
      "2025-07-29 11:21:16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2025-07-29T11:21:16'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = drop_timezone(\"2025-07-29T11:21:16-04:00\")\n",
    "print(ts)\n",
    "ts_parsed = parse_date(ts)\n",
    "print(ts_parsed)\n",
    "datetime_to_iso_with_time(ts_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c326d90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 1, 2025\n",
      "2025-08-01 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2025-08-01T00:00:00'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = \"August 1, 2025\"\n",
    "print(ts)\n",
    "ts_parsed = parse_date(ts,\"Phocusewire\")\n",
    "print(ts_parsed)\n",
    "datetime_to_iso_with_time(ts_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4f47924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skift_web_scraping(last_ingested_date):\n",
    "    base_url = f\"https://skift.com/news/\"\n",
    "    page = 1\n",
    "    max_page = 15\n",
    "    collected_articles = []\n",
    "    last_ingested_date = parse_date(last_ingested_date)\n",
    "    while True:\n",
    "        url = f\"{base_url}page/{page}/\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Stopping due to bad status: {response.status_code} at page {page}\")\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        articles = soup.select(\"article\")\n",
    "\n",
    "        if not articles:\n",
    "            print(f\"No articles found on page {page}, stopping.\")\n",
    "            break\n",
    "\n",
    "        stop_paging = False\n",
    "\n",
    "        for article in articles:\n",
    "            link_tag = article.select_one(\"h3.c-tease__title a\")\n",
    "            news_url = link_tag['href'] if link_tag else None\n",
    "            article_id = generate_article_id(news_url)\n",
    "            headline = link_tag.text.strip() if link_tag else None\n",
    "            print(headline)\n",
    "            author_tag = article.select_one(\"div.c-tease__byline a.underline\")\n",
    "            author_name = author_tag.text.strip() if author_tag else None\n",
    "\n",
    "            time_tag = article.select_one(\"div.c-tease__byline time\")\n",
    "            news_time = drop_timezone(time_tag.get(\"datetime\")) if time_tag else None\n",
    "            news_time = parse_date(news_time)\n",
    "\n",
    "            if news_time:\n",
    "                # If last_ingested_date is set and this article is older or equal, stop ingestion\n",
    "                print(\"News time : \",news_time)\n",
    "                print(\"last -ngested time: \", last_ingested_date)\n",
    "                print(\"-\"*40)\n",
    "                if last_ingested_date and news_time < last_ingested_date:\n",
    "                    stop_paging = True\n",
    "                    print(f\"Encountered article dated {news_time} < last ingested {last_ingested_date}, stopping.\")\n",
    "                    break\n",
    "            else:\n",
    "                # If no date found, you can decide to skip or include\n",
    "                print(\"Article without date found, skipping date check.\")\n",
    "\n",
    "            collected_articles.append({\"Article_id\":article_id,\"News_title\":headline,\"News_link\":news_url,\"Author_name\":author_name,\"News_published_time\":datetime_to_iso_with_time(news_time), \"Source_name\": \"Skift\"})\n",
    "\n",
    "        if stop_paging:\n",
    "            break\n",
    "\n",
    "        page += 1\n",
    "        print(page)\n",
    "    print(\"No. of new articles ingested : \", len(collected_articles))\n",
    "    return collected_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f7d39900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2025-08-01T17:19:21', True)\n",
      "From Concur to Spotnana: Steve Singh on How AI Could Fix Corporate Travel\n",
      "News time :  2025-08-01 17:19:21\n",
      "last -ngested time:  2025-08-01 17:19:21\n",
      "----------------------------------------\n",
      "Delta Responds to AI-Pricing Backlash: No ‘Individualized Prices Based on Personal Data’\n",
      "News time :  2025-08-01 15:05:14\n",
      "last -ngested time:  2025-08-01 17:19:21\n",
      "----------------------------------------\n",
      "Encountered article dated 2025-08-01 15:05:14 < last ingested 2025-08-01 17:19:21, stopping.\n",
      "No. of new articles ingested :  1\n"
     ]
    }
   ],
   "source": [
    "latest_timestamp = get_latest_news_time()\n",
    "print(latest_timestamp)\n",
    "extracted_articles = skift_web_scraping(latest_timestamp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "00bd8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in extracted_articles:\n",
    "    key_list = list(article.keys())\n",
    "    for key in key_list:\n",
    "        if article[key] is None:\n",
    "            print(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e167191a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Article_id': 'b6180012cdfcaab01451bded2196d26c', 'News_title': 'From Concur to Spotnana: Steve Singh on How AI Could Fix Corporate Travel', 'News_link': 'https://skift.com/2025/08/01/from-concur-to-spotnana-steve-singh-on-how-ai-could-fix-corporate-travel/', 'Author_name': \"Sean O'Neill\", 'News_published_time': '2025-08-01T17:19:21', 'Source_name': 'Skift'}\n"
     ]
    }
   ],
   "source": [
    "for article in extracted_articles:\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8444dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_articles(filtered_articles):\n",
    "\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        for article in filtered_articles:\n",
    "            sql = \"\"\"\n",
    "            INSERT INTO articles (Article_id,  News_link, News_title, Author_name, News_published_time, Source_name, Processed_at)\n",
    "            VALUES (?, ?,  ?, ?, ?, ?, CURRENT_TIMESTAMP)\n",
    "            ON CONFLICT(Article_id) DO UPDATE SET\n",
    "                News_link = excluded.News_link,\n",
    "                News_title = excluded.News_title,\n",
    "                Author_name = excluded.Author_name,\n",
    "                News_published_time = excluded.News_published_time,\n",
    "                Source_name = excluded.Source_name,\n",
    "                Processed_at = CURRENT_TIMESTAMP\n",
    "            \"\"\"\n",
    "            params = (\n",
    "                article.get('Article_id'),\n",
    "                article.get('News_link'),\n",
    "                article.get('News_title'),\n",
    "                article.get('Author_name'),\n",
    "                article.get('News_published_time'),\n",
    "                article.get('Source_name'),\n",
    "            )\n",
    "            print(params)\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(sql, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c1ee90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('b6180012cdfcaab01451bded2196d26c', 'https://skift.com/2025/08/01/from-concur-to-spotnana-steve-singh-on-how-ai-could-fix-corporate-travel/', 'From Concur to Spotnana: Steve Singh on How AI Could Fix Corporate Travel', \"Sean O'Neill\", '2025-08-01T17:19:21', 'Skift')\n"
     ]
    }
   ],
   "source": [
    "upsert_articles(extracted_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e1460cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_top5_articles():\n",
    "    # Connect to the SQLite database\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute a query to select all articles\n",
    "        cursor.execute(\"\"\"SELECT Article_id, News_link, News_title,Author_name, News_published_time, Source_name, Processed_at FROM articles\n",
    "                        ORDER BY News_published_time DESC LIMIT 10\"\"\")\n",
    "\n",
    "        # Fetch all rows returned by the query\n",
    "        rows = cursor.fetchall()\n",
    "        # Process and display results\n",
    "        for row in rows:\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7a4ae538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('b6180012cdfcaab01451bded2196d26c', 'https://skift.com/2025/08/01/from-concur-to-spotnana-steve-singh-on-how-ai-could-fix-corporate-travel/', 'From Concur to Spotnana: Steve Singh on How AI Could Fix Corporate Travel', \"Sean O'Neill\", '2025-08-01T17:19:21', 'Skift', '2025-08-02 14:42:42')\n",
      "('d030436466546bcf23aa4befbf4d08b6', 'https://skift.com/2025/08/01/delta-says-it-will-not-use-ai-to-target-customers/', 'Delta Responds to AI-Pricing Backlash: No ‘Individualized Prices Based on Personal Data’', 'Meghna Maharishi', '2025-08-01T15:05:14', 'Skift', '2025-08-02 14:40:49')\n",
      "('8db7ffa1ba14adc8dd8348e7f5d1923d', 'https://skift.com/2025/08/01/u-s-dollar-slide-hurts-accor-minor-and-melia/', 'U.S. Dollar Slide Hurts Accor, Minor, and Meliá', 'Luke Martin', '2025-08-01T13:53:29', 'Skift', '2025-08-02 14:40:49')\n",
      "('3fa30e2c6eee18976f224053633c1a27', 'https://skift.com/2025/08/01/winners-losers-and-lots-of-premium-seats-europes-airline-scorecard/', 'Winners, Losers, and Lots of Premium Seats: Europe’s Airline Scorecard', 'Gordon Smith', '2025-08-01T13:13:39', 'Skift', '2025-08-02 14:40:49')\n",
      "('265b2b2258dd197970b5619cbd6b943a', 'https://skift.com/2025/08/01/electrification-and-renewables-are-driving-iberostars-emissions-decline/', 'Electrification and Renewables Are Driving Iberostar’s Emissions Decline', 'Darin Graham', '2025-08-01T13:02:26', 'Skift', '2025-08-02 14:40:49')\n",
      "('faaffa0546e28c8a42886a98ae4eeb1f', 'https://skift.com/2025/08/01/unmanaged-business-travel-still-dominates-as-smbs-seek-flexible-consumer-style-booking/', 'Unmanaged Business Travel Still Dominates as SMBs Seek Flexible, Consumer-Style Booking', 'Clara Awuse', '2025-08-01T11:57:13', 'Skift', '2025-08-02 14:40:49')\n",
      "('b7b2ec4cf8809f9bf777cfccac1a3ef8', 'https://meetings.skift.com/2025/08/01/from-vegas-to-nashville-elon-musks-loop-targets-event-cities/', 'From Vegas to Nashville: Elon Musk’s Loop Targets Event Cities', 'Andrea Doyle', '2025-08-01T11:04:35', 'Skift', '2025-08-02 14:40:49')\n",
      "('0fe47c1e00042e927192adf61a4108e8', 'https://skift.com/2025/08/01/ihg-pursues-business-travelers-through-emirates-and-other-deals/', 'IHG Pursues Business Travelers Through Emirates and Other Deals', \"Sean O'Neill\", '2025-08-01T09:18:11', 'Skift', '2025-08-02 14:40:49')\n",
      "('6e3d2c63527467198251d568495dee15', 'https://skift.com/2025/08/01/chalet-hotels-names-shwetank-singh-ceo-as-sanjay-sethi-steps-down/', 'Chalet Hotels Names Shwetank Singh CEO As Sanjay Sethi Steps Down', 'Bulbul Dhawan', '2025-08-01T08:22:35', 'Skift', '2025-08-02 14:40:49')\n",
      "('cc4aa88bd65eb2f7db7b96aa58ed8414', 'https://meetings.skift.com/2025/08/01/9-ways-to-kickstart-your-career-as-a-special-event-planner/', '9 Ways to Kickstart Your Career as a Special Event Planner', 'Barbara Scofidio', '2025-08-01T08:18:00', 'Skift', '2025-08-02 14:40:49')\n"
     ]
    }
   ],
   "source": [
    "query_top5_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4e053472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80,)\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute a query to select all articles\n",
    "    cursor.execute(\"\"\"SELECT Count(*) FROM articles\n",
    "                    \"\"\")\n",
    "\n",
    "    # Fetch all rows returned by the query\n",
    "    rows = cursor.fetchall()\n",
    "    # Process and display results\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55529ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) Query target data source, sqlite, and get max time stamp from the data base. -Done\n",
    "2) If timestamp is null return latest_timestamp = '2025-07-01T00:00:00' and incremental = False (meaning do full load from this timestamp)\n",
    " else return latest_timestamp from database and incremental = True. -Done\n",
    "3) Now since website is paginated now query the website from latest page and check for the last news on each page is that smaller then latest_timestamp \n",
    "if yes then stop else go to next page and repeat process.\n",
    "4) once you get all the extracted information, just merge the the extracted information in the database so to avoid any duplicates on last page of news.\n",
    "\n",
    "This will be repeated for the other source too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed37716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
